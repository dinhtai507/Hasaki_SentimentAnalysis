{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder path\n",
    "folder_path = \"D:/HOC KI 8/3. Graduate project/hasaki_crawling/data\"\n",
    "\n",
    "# Add user agen\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
    "\n",
    "# Setting options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"--no-sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ids from crawled csv\n",
    "productdata_filename = \"mergedproduct_20240326_1926.csv\"\n",
    "\n",
    "existing_df = pd.read_csv(os.path.join(folder_path, \"merged\", productdata_filename))\n",
    "existing_product_ids = existing_df['product_id'].tolist()\n",
    "existing_data_product_ids = existing_df['data_product_id'].tolist()\n",
    "existing_links = existing_df['link_item'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 10\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 10\n",
      "Clicked on button next page!\n",
      "Crawl Page 11\n",
      "Clicked on button next page!\n",
      "Crawl Page 12\n",
      "Clicked on button next page!\n",
      "Crawl Page 13\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Next page button not found or not clickable!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 10\n",
      "Clicked on button next page!\n",
      "Crawl Page 11\n",
      "Clicked on button next page!\n",
      "Crawl Page 12\n",
      "Clicked on button next page!\n",
      "Crawl Page 13\n",
      "Clicked on button next page!\n",
      "Crawl Page 14\n",
      "Clicked on button next page!\n",
      "Crawl Page 15\n",
      "Clicked on button next page!\n",
      "Crawl Page 16\n",
      "Clicked on button next page!\n",
      "Crawl Page 17\n",
      "Clicked on button next page!\n",
      "Crawl Page 18\n",
      "Clicked on button next page!\n",
      "Crawl Page 19\n",
      "Clicked on button next page!\n",
      "Crawl Page 20\n",
      "Clicked on button next page!\n",
      "Crawl Page 21\n",
      "Clicked on button next page!\n",
      "Crawl Page 22\n",
      "Clicked on button next page!\n",
      "Crawl Page 23\n",
      "Clicked on button next page!\n",
      "Crawl Page 24\n",
      "Clicked on button next page!\n",
      "Crawl Page 25\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 10\n",
      "Clicked on button next page!\n",
      "Crawl Page 11\n",
      "Clicked on button next page!\n",
      "Crawl Page 12\n",
      "Clicked on button next page!\n",
      "Crawl Page 13\n",
      "Clicked on button next page!\n",
      "Crawl Page 14\n",
      "Clicked on button next page!\n",
      "Crawl Page 15\n",
      "Clicked on button next page!\n",
      "Crawl Page 16\n",
      "Clicked on button next page!\n",
      "Crawl Page 17\n",
      "Clicked on button next page!\n",
      "Crawl Page 18\n",
      "Clicked on button next page!\n",
      "Crawl Page 19\n",
      "Clicked on button next page!\n",
      "Crawl Page 20\n",
      "Clicked on button next page!\n",
      "Crawl Page 21\n",
      "Clicked on button next page!\n",
      "Crawl Page 22\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Next page button not found or not clickable!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 4\n",
      "Clicked on button next page!\n",
      "Crawl Page 5\n",
      "Clicked on button next page!\n",
      "Crawl Page 6\n",
      "Clicked on button next page!\n",
      "Crawl Page 7\n",
      "Clicked on button next page!\n",
      "Crawl Page 8\n",
      "Clicked on button next page!\n",
      "Crawl Page 9\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Next page button not found or not clickable!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n",
      "Crawl Page 2\n",
      "Clicked on button next page!\n",
      "Crawl Page 3\n",
      "Clicked on button next page!\n",
      "Crawl Page 1\n",
      "Clicked on button next page!\n"
     ]
    }
   ],
   "source": [
    "# Get rating for comments:\n",
    "def get_star(string):\n",
    "    start_index = string.find(':')\n",
    "    end_index = string.find('%')\n",
    "    return int(string[start_index+1:end_index]) / 20\n",
    "\n",
    "# Process data-product-id\n",
    "def get_unique_data_productids(nested_list):\n",
    "    unique_ids = set()\n",
    "    for sublist in nested_list:\n",
    "        unique_ids.update(sublist.split(','))\n",
    "    return [id for id in unique_ids]\n",
    "\n",
    "# Parse data_product_id\n",
    "def parse_data_product_id(data_product_id_str):\n",
    "    # Split string by \",\"\n",
    "    id_list = data_product_id_str.split(',')\n",
    "    # Get unique\n",
    "    set_list = set()\n",
    "    set_list.update(id_list)\n",
    "    # Convert each element in the list to an integer and return\n",
    "    return [id_ for id_ in set_list]\n",
    "\n",
    "# ============================ GET INFOMATION OF ALL ITEMS\n",
    "# Declare browser\n",
    "driver = webdriver.Chrome(options=options)\n",
    "sleep(random.randint(1,5))\n",
    "\n",
    "crawled_ids = set()\n",
    "df_list = []\n",
    "# [1:40+1] ~ 1-40\n",
    "# [41:80+1] ~ 41-80\n",
    "# [81:120+1] ~ 81-120\n",
    "for i, row in existing_df[81:120+1].iterrows():\n",
    "    \n",
    "    # Get product page\n",
    "    name_comment, content_comment, product_variant, datetime_comment, rating_comment = [], [], [], [], []\n",
    "    driver.get(row['link_item'])\n",
    "    sleep(random.randint(6,7))\n",
    "    \n",
    "    # Get data_product_id_list\n",
    "    elems_data_productids_list = driver.find_elements(By.CSS_SELECTOR, '.attribute-option-item')\n",
    "    uniq_data_productids_list = parse_data_product_id(\",\".join([elem.get_attribute('data-product-ids') for elem in elems_data_productids_list]))\n",
    "    uniq_data_product_id_str = \",\".join(uniq_data_productids_list)\n",
    "\n",
    "    # Get comment_pagination_number\n",
    "    elems_cmtpage_nums = driver.find_elements(By.CSS_SELECTOR, '.pagination_comment a')\n",
    "    if elems_cmtpage_nums:\n",
    "        commentpage_nums = [int(elem.get_attribute('rel')) for elem in elems_cmtpage_nums\n",
    "                        if elem.get_attribute('rel').isdigit()]\n",
    "        max_cmtpage = max(commentpage_nums) if commentpage_nums else 1\n",
    "    else:\n",
    "        max_cmtpage = 1\n",
    "\n",
    "    # Decide whether to crawl\n",
    "    if not set(uniq_data_productids_list).intersection(crawled_ids):\n",
    "        # Get comment details\n",
    "        for page_num in range(1, max_cmtpage + 1):\n",
    "            try:\n",
    "                sleep(random.randint(2,3))\n",
    "                \n",
    "                print(\"Crawl Page \" + str(page_num))\n",
    "                elems_name = driver.find_elements(By.CSS_SELECTOR , \".title_comment strong.txt_color_1\")\n",
    "                name_comment = [elem.text for elem in elems_name] + name_comment\n",
    "                sleep(random.randint(1,2))\n",
    "\n",
    "                elems_content = driver.find_elements(By.CSS_SELECTOR , \".item_comment .content_comment\")\n",
    "                content_comment = [elem.text for elem in elems_content] + content_comment\n",
    "                sleep(random.randint(1,2))\n",
    "\n",
    "                elems_product_variant = driver.find_elements(By.CSS_SELECTOR , \".item_comment .txt_999\")\n",
    "                product_variant = [elem.text for elem in elems_product_variant] + product_variant\n",
    "                sleep(random.randint(1,2))\n",
    "\n",
    "                elems_datetime = driver.find_elements(By.CSS_SELECTOR , \".item_comment .timer_comment\")\n",
    "                datetime_comment = [elem.text for elem in elems_datetime] + datetime_comment\n",
    "                sleep(random.randint(1,2))\n",
    "\n",
    "                elems_rating = driver.find_elements(By.CSS_SELECTOR , \".item_comment .number_start\")\n",
    "                rating_comment = [get_star(elem.get_attribute('style')) for elem in elems_rating] + rating_comment\n",
    "                sleep(random.randint(1,2))\n",
    "                \n",
    "                next_pagination_cmt = driver.find_element(By.CSS_SELECTOR, \"a.item_next_sort .icon_carret_down\")\n",
    "                next_pagination_cmt.click()\n",
    "\n",
    "                print(\"Clicked on button next page!\")\n",
    "                sleep(random.randint(2,3))\n",
    "\n",
    "            except ElementNotInteractableException:\n",
    "                print(\"Element Not Interactable Exception!\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                print(\"Next page button not found or not clickable!\")\n",
    "                break        \n",
    "\n",
    "        # Add into a dataframe\n",
    "        comment_data = pd.DataFrame(\n",
    "            list(zip(name_comment, content_comment, product_variant, datetime_comment, rating_comment)), \n",
    "            columns = ['name_comment', 'content_comment','product_variant', 'datetime_comment', 'rating'])\n",
    "        \n",
    "        # Add column \"link_item\", \"data_product_id_list\", \"data_product_id\"\n",
    "        comment_data.insert(0, \"link_item\", row['link_item'])\n",
    "        comment_data.insert(1, \"data_product_id_list\", uniq_data_product_id_str)\n",
    "        comment_data.insert(2, \"data_product_id\", row['data_product_id'])\n",
    "        \n",
    "        # For \"data_product_id_list\", convert string into list\n",
    "        comment_data['data_product_id_list'] = comment_data['data_product_id_list'].apply(parse_data_product_id)\n",
    "        df_list.append(comment_data)\n",
    "\n",
    "        crawled_ids.update(uniq_data_productids_list)\n",
    "        sleep(random.randint(6,7))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_item</th>\n",
       "      <th>data_product_id_list</th>\n",
       "      <th>data_product_id</th>\n",
       "      <th>name_comment</th>\n",
       "      <th>content_comment</th>\n",
       "      <th>product_variant</th>\n",
       "      <th>datetime_comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...</td>\n",
       "      <td>[54724, 118388, 115591, 106547, 80571, 108078,...</td>\n",
       "      <td>54724</td>\n",
       "      <td>Nguyễn Vũ Trúc Thư</td>\n",
       "      <td>Sp tốt</td>\n",
       "      <td>Gel Rửa Mặt SVR Dành Cho Da Dầu 200ml Đã mua h...</td>\n",
       "      <td>15: 59 | 26/10/2019</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...</td>\n",
       "      <td>[54724, 118388, 115591, 106547, 80571, 108078,...</td>\n",
       "      <td>54724</td>\n",
       "      <td>HOANG OANH</td>\n",
       "      <td>Sử dụng thấy rất hiệu quả</td>\n",
       "      <td>Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...</td>\n",
       "      <td>16: 30 | 14/07/2021</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...</td>\n",
       "      <td>[54724, 118388, 115591, 106547, 80571, 108078,...</td>\n",
       "      <td>54724</td>\n",
       "      <td>nguyễn ngọc kim ngân</td>\n",
       "      <td>Sữa rửa mặt này sử dụng siêu đã và thích lắm ạ...</td>\n",
       "      <td>Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...</td>\n",
       "      <td>21: 11 | 20/06/2021</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...</td>\n",
       "      <td>[54724, 118388, 115591, 106547, 80571, 108078,...</td>\n",
       "      <td>54724</td>\n",
       "      <td>Nam Thương</td>\n",
       "      <td>Cái này tắm thì được, dùng cho mặt sạch, nhưng...</td>\n",
       "      <td>Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...</td>\n",
       "      <td>01: 40 | 12/04/2021</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...</td>\n",
       "      <td>[54724, 118388, 115591, 106547, 80571, 108078,...</td>\n",
       "      <td>54724</td>\n",
       "      <td>Tiểu Tiểu</td>\n",
       "      <td>Da mình da ít dầu ít mụn dùng bé này khá ok nh...</td>\n",
       "      <td>Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...</td>\n",
       "      <td>01: 25 | 11/04/2021</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           link_item  \\\n",
       "0  https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...   \n",
       "1  https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...   \n",
       "2  https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...   \n",
       "3  https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...   \n",
       "4  https://hasaki.vn/san-pham/gel-rua-mat-svr-kho...   \n",
       "\n",
       "                                data_product_id_list  data_product_id  \\\n",
       "0  [54724, 118388, 115591, 106547, 80571, 108078,...            54724   \n",
       "1  [54724, 118388, 115591, 106547, 80571, 108078,...            54724   \n",
       "2  [54724, 118388, 115591, 106547, 80571, 108078,...            54724   \n",
       "3  [54724, 118388, 115591, 106547, 80571, 108078,...            54724   \n",
       "4  [54724, 118388, 115591, 106547, 80571, 108078,...            54724   \n",
       "\n",
       "           name_comment                                    content_comment  \\\n",
       "0    Nguyễn Vũ Trúc Thư                                             Sp tốt   \n",
       "1            HOANG OANH                          Sử dụng thấy rất hiệu quả   \n",
       "2  nguyễn ngọc kim ngân  Sữa rửa mặt này sử dụng siêu đã và thích lắm ạ...   \n",
       "3            Nam Thương  Cái này tắm thì được, dùng cho mặt sạch, nhưng...   \n",
       "4             Tiểu Tiểu  Da mình da ít dầu ít mụn dùng bé này khá ok nh...   \n",
       "\n",
       "                                     product_variant     datetime_comment  \\\n",
       "0  Gel Rửa Mặt SVR Dành Cho Da Dầu 200ml Đã mua h...  15: 59 | 26/10/2019   \n",
       "1  Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...  16: 30 | 14/07/2021   \n",
       "2  Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...  21: 11 | 20/06/2021   \n",
       "3  Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...  01: 40 | 12/04/2021   \n",
       "4  Gel Rửa Mặt SVR Không Chứa Xà Phòng Cho Da Dầu...  01: 25 | 11/04/2021   \n",
       "\n",
       "   rating  \n",
       "0     5.0  \n",
       "1     5.0  \n",
       "2     5.0  \n",
       "3     3.0  \n",
       "4     5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all comment crawled\n",
    "combined_comment_data = pd.concat(df_list, ignore_index=True)\n",
    "combined_comment_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into csv\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "comment_data_file_name = f\"comment_data_{current_datetime}.csv\"\n",
    "combined_comment_data.to_csv(os.path.join(folder_path, \"comment\", comment_data_file_name), encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
